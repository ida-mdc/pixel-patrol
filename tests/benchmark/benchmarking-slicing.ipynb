{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "099e147f-2559-4387-8935-233f5d6cc239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import laplace\n",
    "\n",
    "def op_mean(array_2d):\n",
    "    \"\"\"Plain mean of a 2D array.\"\"\"\n",
    "    return np.mean(array_2d)\n",
    "\n",
    "def op_mean_laplace(array_2d):\n",
    "    \"\"\"Mean of the laplacian of a 2D array.\"\"\"\n",
    "    return np.mean(laplace(array_2d))\n",
    "\n",
    "def op_std_dev(array_2d):\n",
    "    \"\"\"Standard deviation of a 2D array.\"\"\"\n",
    "    return np.std(array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931046cd-349c-4c81-b943-2d6362731eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# --- Setup Dask Client ---\n",
    "client = Client(LocalCluster(n_workers=4, threads_per_worker=2, memory_limit='16GB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d53669-e48a-4d6d-a0e9-8ba3301b145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def run_dask_benchmark(methods_to_test, shapes_to_test, chunk_configs_func, n_trials=3):\n",
    "    \"\"\"\n",
    "    Runs the benchmark by loading data from Zarr stores on disk.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    base_dir = \"dask_data\"\n",
    "\n",
    "    for shape in shapes_to_test:\n",
    "        chunk_configs = chunk_configs_func(shape)\n",
    "        for chunk_name in chunk_configs.keys(): # Iterate by name\n",
    "            print(f\"\\n--- Shape: {shape} | Chunks: {chunk_name} ---\")\n",
    "            \n",
    "            shape_str = 'x'.join(map(str, shape))\n",
    "            path = os.path.join(base_dir, f\"data_{shape_str}_{chunk_name}.zarr\")\n",
    "            \n",
    "            # Load the array lazily from disk\n",
    "            dask_arr = da.from_zarr(path)\n",
    "            \n",
    "            for method_name, core_func in methods_to_test.items():\n",
    "                print(f\"  -> Testing Method: {method_name}...\")\n",
    "                \n",
    "                for _ in range(n_trials):\n",
    "                    start = time.perf_counter()\n",
    "                    # The computation itself remains the same\n",
    "                    da.apply_gufunc(core_func, \"(i,j)->()\", dask_arr).compute()\n",
    "                    end = time.perf_counter()\n",
    "                    results.append({\n",
    "                        'method': method_name, \n",
    "                        'shape': str(shape), \n",
    "                        'chunks': chunk_name, \n",
    "                        'time': end - start\n",
    "                    })\n",
    "            \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41d9418-646e-41cc-9412-1d25c5e75974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.array as da\n",
    "import zarr # You may need to install this: pip install zarr\n",
    "\n",
    "def prepare_datasets(shapes_to_test, chunk_configs_func):\n",
    "    \"\"\"\n",
    "    Generates Dask arrays and saves them to disk in Zarr format.\n",
    "    \"\"\"\n",
    "    print(\"--- Preparing and saving datasets to disk ---\")\n",
    "    base_dir = \"dask_data\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    for shape in shapes_to_test:\n",
    "        chunk_configs = chunk_configs_func(shape)\n",
    "        for chunk_name, chunks in chunk_configs.items():\n",
    "            shape_str = 'x'.join(map(str, shape))\n",
    "            # Define a unique path for each dataset configuration\n",
    "            path = os.path.join(base_dir, f\"data_{shape_str}_{chunk_name}.zarr\")\n",
    "            \n",
    "            if os.path.exists(path):\n",
    "                print(f\"  -> Dataset already exists: {path}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"  -> Creating dataset: {path}\")\n",
    "            # Create a random array\n",
    "            dask_arr = da.random.random(size=shape, chunks=chunks)\n",
    "            # Save it to a Zarr store on disk\n",
    "            dask_arr.to_zarr(path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24bb0eb-8390-4449-b2e7-e8d0150bf37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing and saving datasets to disk ---\n",
      "  -> Creating dataset: dask_data/data_500x500_Small.zarr\n",
      "  -> Creating dataset: dask_data/data_500x500_Sliced.zarr\n",
      "  -> Creating dataset: dask_data/data_500x500_Ideal.zarr\n",
      "  -> Creating dataset: dask_data/data_500x500_Realistic.zarr\n",
      "  -> Creating dataset: dask_data/data_4x500x500_Small.zarr\n",
      "  -> Creating dataset: dask_data/data_4x500x500_Sliced.zarr\n",
      "  -> Creating dataset: dask_data/data_4x500x500_Ideal.zarr\n",
      "  -> Creating dataset: dask_data/data_4x500x500_Realistic.zarr\n",
      "  -> Creating dataset: dask_data/data_50x50x4x500_Small.zarr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/distributed/client.py:3363: UserWarning: Sending large graph of size 61.67 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Creating dataset: dask_data/data_50x50x4x500_Sliced.zarr\n",
      "  -> Creating dataset: dask_data/data_50x50x4x500_Ideal.zarr\n",
      "  -> Creating dataset: dask_data/data_50x50x4x500_Realistic.zarr\n",
      "  -> Creating dataset: dask_data/data_50x50x4x500x500_Small.zarr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/distributed/client.py:3363: UserWarning: Sending large graph of size 2.41 GiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Creating dataset: dask_data/data_50x50x4x500x500_Sliced.zarr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/distributed/client.py:3363: UserWarning: Sending large graph of size 24.81 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Creating dataset: dask_data/data_50x50x4x500x500_Ideal.zarr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 13:55:35,332 - distributed.worker - ERROR - Compute Failed\n",
      "Key:       ('random_sample-store-map-06b51e628cfba7cf4a23f534493c940e', 1, 1, 1, 0, 0)\n",
      "State:     executing\n",
      "Task:  <Task ('random_sample-store-map-06b51e628cfba7cf4a23f534493c940e', 1, 1, 1, 0, 0) _execute_subgraph(...)>\n",
      "Exception: \"ValueError('Codec does not support buffers of > 2147483647 bytes')\"\n",
      "Traceback: '  File \"/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/dask/array/core.py\", line 4617, in load_store_chunk\\n    out[index] = x\\n    ~~~^^^^^^^\\n  File \"/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py\", line 1449, in __setitem__\\n    self.set_orthogonal_selection(pure_selection, value, fields=fields)\\n  File \"/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py\", line 1638, in set_orthogonal_selection\\n    self._set_selection(indexer, value, fields=fields)\\n  File \"/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py\", line 1990, in _set_selection\\n    self._chunk_setitem(chunk_coords, chunk_selection, chunk_value, fields=fields)\\n  File \"/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py\", line 2263, in _chunk_setitem\\n    self._chunk_setitem_nosync(chunk_coords, chunk_selection, value, fields=fields)\\n  File \"/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py\", line 2273, in _chunk_setitem_nosync\\n    self.chunk_store[ckey] = self._encode_chunk(cdata)\\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py\", line 2397, in _encode_chunk\\n    cdata = self._compressor.encode(chunk)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"numcodecs/blosc.pyx\", line 580, in numcodecs.blosc.Blosc.encode\\n  File \"/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/numcodecs/compat.py\", line 149, in ensure_contiguous_ndarray\\n    ensure_contiguous_ndarray_like(buf, max_buffer_size=max_buffer_size, flatten=flatten)\\n  File \"/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/numcodecs/compat.py\", line 115, in ensure_contiguous_ndarray_like\\n    raise ValueError(msg)\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Codec does not support buffers of > 2147483647 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     25\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSmall\u001b[39m\u001b[33m\"\u001b[39m: (*[\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m other_dims], \u001b[32m50\u001b[39m, \u001b[32m50\u001b[39m),\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSliced\u001b[39m\u001b[33m\"\u001b[39m: (*[\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m other_dims], n, m),\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIdeal\u001b[39m\u001b[33m\"\u001b[39m: (*[d//\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m d > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m other_dims], n, m),\n\u001b[32m     28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRealistic\u001b[39m\u001b[33m\"\u001b[39m: (*[d//\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m d > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m other_dims], n//\u001b[32m4\u001b[39m, m//\u001b[32m4\u001b[39m),\n\u001b[32m     29\u001b[39m     }\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# --- Execute and Plot ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mprepare_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSHAPES_TO_TEST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_chunk_configs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m df_results = run_dask_benchmark(METHODS_TO_TEST, SHAPES_TO_TEST, get_chunk_configs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mprepare_datasets\u001b[39m\u001b[34m(shapes_to_test, chunk_configs_func)\u001b[39m\n\u001b[32m     26\u001b[39m dask_arr = da.random.random(size=shape, chunks=chunks)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Save it to a Zarr store on disk\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mdask_arr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/dask/array/core.py:3022\u001b[39m, in \u001b[36mArray.to_zarr\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3011\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_zarr\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   3012\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Save array to the zarr storage format\u001b[39;00m\n\u001b[32m   3013\u001b[39m \n\u001b[32m   3014\u001b[39m \u001b[33;03m    See https://zarr.readthedocs.io for details about the format.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3020\u001b[39m \u001b[33;03m    dask.array.to_zarr : equivalent function\u001b[39;00m\n\u001b[32m   3021\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/dask/array/core.py:3943\u001b[39m, in \u001b[36mto_zarr\u001b[39m\u001b[34m(arr, url, component, storage_options, overwrite, region, compute, return_stored, **kwargs)\u001b[39m\n\u001b[32m   3932\u001b[39m chunks = [c[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m arr.chunks]\n\u001b[32m   3934\u001b[39m z = zarr.create(\n\u001b[32m   3935\u001b[39m     shape=arr.shape,\n\u001b[32m   3936\u001b[39m     chunks=chunks,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3941\u001b[39m     **kwargs,\n\u001b[32m   3942\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3943\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_stored\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_stored\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/dask/array/core.py:1795\u001b[39m, in \u001b[36mArray.store\u001b[39m\u001b[34m(self, target, **kwargs)\u001b[39m\n\u001b[32m   1793\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(store)\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstore\u001b[39m(\u001b[38;5;28mself\u001b[39m, target, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1795\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/dask/array/core.py:1227\u001b[39m, in \u001b[36mstore\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_stored:\n\u001b[32m   1225\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdask\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1227\u001b[39m     \u001b[43mdask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1229\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/dask/base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py:1449\u001b[39m, in \u001b[36m__setitem__\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1447\u001b[39m     \u001b[38;5;28mself\u001b[39m.vindex[selection] = value\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_pure_orthogonal_indexing(pure_selection, \u001b[38;5;28mself\u001b[39m.ndim):\n\u001b[32m-> \u001b[39m\u001b[32m1449\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_orthogonal_selection(pure_selection, value, fields=fields)\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1451\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_basic_selection(pure_selection, value, fields=fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py:1638\u001b[39m, in \u001b[36mset_orthogonal_selection\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1635\u001b[39m \u001b[38;5;66;03m# setup indexer\u001b[39;00m\n\u001b[32m   1636\u001b[39m indexer = OrthogonalIndexer(selection, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1638\u001b[39m \u001b[38;5;28mself\u001b[39m._set_selection(indexer, value, fields=fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py:1990\u001b[39m, in \u001b[36m_set_selection\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1987\u001b[39m                 chunk_value = chunk_value[item]\n\u001b[32m   1989\u001b[39m         \u001b[38;5;66;03m# put data\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1990\u001b[39m         \u001b[38;5;28mself\u001b[39m._chunk_setitem(chunk_coords, chunk_selection, chunk_value, fields=fields)\n\u001b[32m   1991\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1992\u001b[39m     lchunk_coords, lchunk_selection, lout_selection = \u001b[38;5;28mzip\u001b[39m(*indexer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py:2263\u001b[39m, in \u001b[36m_chunk_setitem\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2260\u001b[39m     lock = \u001b[38;5;28mself\u001b[39m._synchronizer[ckey]\n\u001b[32m   2262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[32m-> \u001b[39m\u001b[32m2263\u001b[39m     \u001b[38;5;28mself\u001b[39m._chunk_setitem_nosync(chunk_coords, chunk_selection, value, fields=fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py:2273\u001b[39m, in \u001b[36m_chunk_setitem_nosync\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2271\u001b[39m     \u001b[38;5;28mself\u001b[39m._chunk_delitem(ckey)\n\u001b[32m   2272\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2273\u001b[39m     \u001b[38;5;28mself\u001b[39m.chunk_store[ckey] = \u001b[38;5;28mself\u001b[39m._encode_chunk(cdata)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/zarr/core.py:2397\u001b[39m, in \u001b[36m_encode_chunk\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2395\u001b[39m \u001b[38;5;66;03m# compress\u001b[39;00m\n\u001b[32m   2396\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compressor:\n\u001b[32m-> \u001b[39m\u001b[32m2397\u001b[39m     cdata = \u001b[38;5;28mself\u001b[39m._compressor.encode(chunk)\n\u001b[32m   2398\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2399\u001b[39m     cdata = chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumcodecs/blosc.pyx:580\u001b[39m, in \u001b[36mnumcodecs.blosc.Blosc.encode\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/numcodecs/compat.py:149\u001b[39m, in \u001b[36mensure_contiguous_ndarray\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mensure_contiguous_ndarray\u001b[39m(buf, max_buffer_size=\u001b[38;5;28;01mNone\u001b[39;00m, flatten=\u001b[38;5;28;01mTrue\u001b[39;00m) -> np.ndarray:\n\u001b[32m    121\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convenience function to coerce `buf` to a numpy array, if it is not already a\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[33;03m    numpy array. Also ensures that the returned value exports fully contiguous memory,\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[33;03m    and supports the new-style buffer interface. If the optional max_buffer_size is\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m \u001b[33;03m    return a view on memory exported by `buf`.\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_ndarray(\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m         ensure_contiguous_ndarray_like(buf, max_buffer_size=max_buffer_size, flatten=flatten)\n\u001b[32m    150\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/data/Development/hi/repos/pixel-patrol/.venv/lib/python3.12/site-packages/numcodecs/compat.py:115\u001b[39m, in \u001b[36mensure_contiguous_ndarray_like\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_buffer_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m arr.nbytes > max_buffer_size:\n\u001b[32m    114\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCodec does not support buffers of > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_buffer_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m bytes\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[31mValueError\u001b[39m: Codec does not support buffers of > 2147483647 bytes"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Define Test Configurations ---\n",
    "METHODS_TO_TEST = {\n",
    "    \"Mean\": op_mean,\n",
    "    \"Mean Laplace\": op_mean_laplace,\n",
    "}\n",
    "\n",
    "xy_size = 500\n",
    "other_size = 50\n",
    "\n",
    "SHAPES_TO_TEST = [\n",
    "    (xy_size, xy_size),\n",
    "    (4, xy_size, xy_size),\n",
    "    (other_size, other_size, 4, xy_size),\n",
    "    (other_size, other_size, 4, xy_size, xy_size)\n",
    "]\n",
    "\n",
    "def get_chunk_configs(shape):\n",
    "    # Same function as before\n",
    "    n, m = shape[-2], shape[-1]\n",
    "    other_dims = shape[:-2] if len(shape) > 2 else ()\n",
    "    return {\n",
    "        \"Small\": (*[1 for d in other_dims], 50, 50),\n",
    "        \"Sliced\": (*[1 for d in other_dims], n, m),\n",
    "        \"Ideal\": (*[d//2 if d > 1 else 1 for d in other_dims], n, m),\n",
    "        \"Realistic\": (*[d//2 if d > 1 else 1 for d in other_dims], n//4, m//4),\n",
    "    }\n",
    "\n",
    "# --- Execute and Plot ---\n",
    "prepare_datasets(SHAPES_TO_TEST, get_chunk_configs)\n",
    "df_results = run_dask_benchmark(METHODS_TO_TEST, SHAPES_TO_TEST, get_chunk_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14771816-2083-4b4e-b96d-cd9dd865df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_dask_results(df):\n",
    "    \"\"\"\n",
    "    Generates and saves a separate plot for each benchmarked method,\n",
    "    comparing chunking strategies.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Generating Dask performance plots ---\")\n",
    "    \n",
    "    for method_name in df['method'].unique():\n",
    "        print(f\"  -> Creating plot for: {method_name}\")\n",
    "        \n",
    "        df_method = df[df['method'] == method_name]\n",
    "        \n",
    "        g = sns.catplot(\n",
    "            data=df_method,\n",
    "            kind=\"bar\",\n",
    "            col=\"shape\",      # Create a subplot column for each shape\n",
    "            x=\"chunks\",       # Compare chunking strategies on the x-axis\n",
    "            y=\"time\",\n",
    "            sharey=False,\n",
    "            height=6,\n",
    "            aspect=1.0\n",
    "        )\n",
    "        \n",
    "        # Configure titles and labels\n",
    "        g.set_axis_labels(\"Chunking Strategy\", \"Execution Time (s)\")\n",
    "        g.set_titles(\"Shape: {col_name}\")\n",
    "        g.fig.suptitle(f\"Dask Performance for: {method_name}\", y=1.03, fontsize=16)\n",
    "        \n",
    "        # Create a dynamic filename for each plot\n",
    "        safe_filename = method_name.lower().replace(' ', '_')\n",
    "        output_filename = f'dask_benchmark_{safe_filename}.png'\n",
    "        \n",
    "        # Save the figure\n",
    "        g.figure.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"     ✅ Plot saved to {output_filename}\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close(g.fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471989a4-7741-4d0a-aad8-9d8dac7be749",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dask_results(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15c192-cb30-4a10-ac9f-dd39f552e511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
